{
  "goal": "# Pricing and Product Coverage Roadmap\n\nThis file turns the product and model expansion roadmap into trackable milestones\nwith measurable acceptance criteria. Update statuses as work lands.\n\n## How to use\n- Keep phases in order; update status and checkboxes as items complete.\n- Tie acceptance criteria to tests and report outputs whenever possible.\n- See `docs/success_metrics.md` for thresholds and reporting targets.\n\n## Current baseline (implemented)\n- Products: spot, forwards, equity swaps, European and American options, barriers,\n  digitals, Asians, lookbacks, cliquets, corridors, variance swaps, vol swaps,\n  basket proxy.\n- Models: Black-Scholes, Heston, Merton, local vol (placeholder), local-stochastic\n  vol (leverage surface), hybrid LSV proxy.\n- Engines: analytic, tree, PDE, Monte Carlo (LSM for Americans, Brownian bridge,\n  variance reduction toggles, Halton QMC).\n- Risk workflow: historical VaR/ES, FRTB IMA liquidity-horizon aggregation,\n  PLA/backtesting, RTPL grid sensitivities, grid approximation/checks.\n- Reporting: JSON/CSV/HTML reports and run logs with schema metadata.\n\n## Phase 1 - Stabilize core vanilla coverage (4-6 weeks)\nStatus: complete\n\nDeliverables\n- [x] Deterministic Monte Carlo via seeded `EngineSettings`.\n- [x] Cross-engine parity tests for European options (analytic vs tree vs PDE).\n- [x] Auto Greek method: analytic for BS European options, bump fallback otherwise.\n- [x] Greek stability tests (delta/gamma/vega) against bump size halving.\n\nAcceptance criteria\n- Parity test passes within abs 1e-2 or rel 1e-3 for BS European calls.\n- Deterministic Monte Carlo produces identical prices with fixed seed.\n- Bump Greek stability within 2-5 percent when bump size is halved.\n\n## Phase 2 - Barrier and digital coverage (6-8 weeks)\nStatus: complete\n\nDeliverables\n- [x] PDE or analytic pricing for standard barrier types (up/down, in/out).\n- [x] Monte Carlo continuous monitoring with Brownian bridge validation cases.\n- [x] Digital pricing parity across analytic and MC for BS.\n\nAcceptance criteria\n- Barrier PDE/MC prices match analytic benchmarks (where available) within 2 percent.\n- Brownian bridge barrier price is less than or equal to discrete monitoring.\n- Digital option prices across engines within 2 percent for BS scenarios.\n\n## Phase 3 - Asian, lookback, cliquet, corridor coverage (8-10 weeks)\nStatus: in progress\n\nDeliverables\n- [x] Monte Carlo variance reduction toggles (antithetic, control variate,\n  moment matching, Halton QMC).\n- [ ] Path-dependent payoff regression tests for Asian, lookback, cliquet, corridor.\n- [ ] Monte Carlo stderr and config metadata propagated into pricing results and reports.\n- [ ] Convergence sweep utility (paths/seed grid) with report outputs.\n\nAcceptance criteria\n- MC standard error shrinks roughly with 1/sqrt(N) across path products.\n- Variance reduction reduces stderr by at least 25 percent at fixed paths.\n- Pricing reports include stderr, confidence intervals, and MC configuration metadata.\n- Regression tests match analytic or benchmark prices within 2-5 percent.\n\n## Phase 4 - Volatility and variance swaps (8-12 weeks)\nStatus: in progress\n\nDeliverables\n- [x] Static replication from surface for variance swap fair strikes.\n- [x] Vol swap pricing with variance-to-vol conversion and bias checks.\n- [x] Monte Carlo realized variance/vol pricing.\n- [ ] Corridor variance swap pricing with surface integration and MC fallback.\n- [ ] Benchmark tests for variance/vol swap parity (analytic vs MC).\n\nAcceptance criteria\n- Variance swap fair strike matches analytic surface integration benchmarks.\n- MC realized variance estimates converge to analytic fair strike within 2 percent.\n- Vol swap prices are within 2-3 percent of sqrt-variance benchmarks under BS.\n\n## Phase 5 - Model expansion and calibration depth (12-16 weeks)\nStatus: in progress\n\nDeliverables\n- [x] Local-stochastic vol calibration pipeline (direct leverage + particle).\n- [ ] Calibration stability checks (parameter bounds, fit diagnostics, sanity).\n- [ ] Local vol surface bootstrapping with arbitrage checks.\n- [ ] Heston/Merton calibration to implied vol smiles.\n- [ ] Model/engine compatibility matrix with coverage notes in docs.\n\nAcceptance criteria\n- LSV calibration produces stable leverage surfaces across tenors.\n- Calibration diagnostics saved with run metadata and reproducible seeds.\n- Calibration errors meet `docs/success_metrics.md` thresholds.\n\n## Phase 6 - Portfolio and risk workflow enhancements (ongoing)\nStatus: in progress\n\nDeliverables\n- [x] Standardized pricing and risk artifacts (JSON/CSV/HTML) with schema metadata.\n- [x] Grid approximation diagnostics and sensitivity check reports.\n- [ ] Scenario pricing artifacts aligned with market risk reports.\n- [ ] Stress testing library (historical + macro scenarios) with report templates.\n- [ ] Performance profiling, caching, and parallelization hooks for portfolio-scale runs.\n- [ ] Risk factor mapping and desk approval workflow wiring.\n\nAcceptance criteria\n- Pricing and risk reports share consistent schema versioning.\n- Scenario pricing artifacts align with `docs/reporting.md` definitions.\n- Stress reports include scenario metadata and reproducible inputs.\n- Runtime targets meet `docs/success_metrics.md` thresholds.\n\n## Phase 7 - Market data and curve/surface industrialization (12-20 weeks)\nStatus: planned\n\nDeliverables\n- [ ] Curve bootstrapping (OIS, futures, swaps) with multi-curve support.\n- [ ] Vol surface calibration with arbitrage checks and extrapolation rules.\n- [ ] Corporate actions, calendars, and day-count conventions in market data pipeline.\n- [ ] Data quality rules, lineage tracking, and versioned snapshots.\n\nAcceptance criteria\n- Bootstrap curves replicate input quotes within tolerance.\n- Surface no-arbitrage checks pass across tenors and strikes.\n- Snapshot lineage supports reproducible pricing/risk runs.\n\n## Phase 8 - Cross-asset expansion (16-24 weeks)\nStatus: planned\n\nDeliverables\n- [ ] FX, rates, credit, and commodities product libraries.\n- [ ] Multi-asset correlation and cross-risk-factor simulation.\n- [ ] Multi-curve discounting and collateralization conventions.\n- [ ] Basket and hybrid products beyond proxy approximations.\n\nAcceptance criteria\n- Cross-asset parity and calibration tests pass within defined tolerances.\n- Portfolio risk aggregates across asset classes with consistent risk factors.\n\n## Phase 9 - Counterparty credit and XVA (16-24 weeks)\nStatus: planned\n\nDeliverables\n- [ ] Exposure profiles (EPE/PFE) with netting/CSA terms.\n- [ ] CVA/DVA/FVA/MVA/KVA calculations and reporting.\n- [ ] Wrong-way risk toggles and stress scenario integration.\n\nAcceptance criteria\n- XVA reports reconcile against exposure profiles and market data.\n- Stress scenarios produce explainable shifts with audit trails.\n\n## Phase 10 - Productionization and governance (ongoing)\nStatus: planned\n\nDeliverables\n- [ ] Model risk governance (validation evidence, approvals, versioning).\n- [ ] Batch orchestration, distributed compute, and storage for large portfolios.\n- [ ] Monitoring, SLAs, and alerting for pricing/risk services.\n- [ ] Secure APIs, permissioning, and audit logs.\n\nAcceptance criteria\n- Reproducible runs with immutable inputs and outputs.\n- Performance and availability targets meet business SLAs.",
  "instructions": "ROLE: Implementer\n\nGoal\n- Apply code changes that satisfy the Planner output and the overall request.\n\nInstructions\n- Modify the codebase directly; keep changes minimal and well-scoped.\n- Apply real file edits in the repo (not just a plan or description).\n- Note any assumptions or tradeoffs made while implementing.\n- If no edits are needed, explain why; if blocked, report it clearly.\n\nOutput\nReturn a JSON object between the markers below:\n===RESULT===\n{\n  \"changes\": [\n    {\"file\": \"path\", \"summary\": \"...\"}\n  ],\n  \"tests_needed\": [\"...\"],\n  \"notes\": [\"...\"],\n  \"open_questions\": [\"...\"]\n}\n===END===\n",
  "past_rounds": [],
  "previous_outputs": {
    "planner": {
      "acceptance_criteria": [
        "Pricing reports include MC `stderr`, confidence interval fields, and engine settings metadata for MC trades, validated by updated tests in `tests/test_reporting.py`.",
        "Path-dependent regression tests for Asian, lookback, cliquet, and corridor pass within 2-5% of benchmark values using deterministic seeds.",
        "Convergence sweep reports show stderr scaling ~1/sqrt(N) across at least three path counts and variance reduction improves stderr by >= 25% at fixed paths.",
        "Corridor variance swap fair strikes from surface integration match MC within 2-3% for BS scenarios and respect corridor bounds.",
        "Variance/vol swap parity tests (analytic vs MC) pass within 2-3% under BS for multiple market scenarios.",
        "Calibration diagnostics (bounds checks, fit errors, seeds) are persisted and meet thresholds from `docs/success_metrics.md`.",
        "Scenario pricing artifacts follow `docs/reporting.md` meta schema and are written to the expected report directories.",
        "Runtime targets in `docs/success_metrics.md` remain satisfied for the sample pricing and mock risk workflows after changes."
      ],
      "improvements": [
        "Link each roadmap deliverable to a specific test or report artifact (test name + script path) to make status updates objective.",
        "Add a small `tests/benchmarks/` dataset with a rebaseline script to keep regression values auditable and reproducible.",
        "Expand `docs/reporting.md` to include MC diagnostics fields and a convergence sweep report type for schema consistency.",
        "Split stochastic tests into deterministic vs statistical buckets to avoid flaky CI while still validating convergence behavior.",
        "Add lightweight performance timing in pricing runs to track runtime targets from `docs/success_metrics.md`."
      ],
      "plan": [
        "Define MC diagnostics schema (stderr, confidence intervals, config) and propagate from `pricing_engine/numerics/monte_carlo.py` through `pricing_engine/api.py` into `pricing_engine/run_pricing_report.py`, plus update `pricing_engine/reporting.py` and `tests/test_reporting.py`.",
        "Create path-dependent regression tests for Asian, lookback, cliquet, and corridor in `tests/` using `market_scenarios` fixtures and deterministic seeds, with benchmark values stored under `tests/benchmarks/`.",
        "Implement a convergence sweep runner (e.g., `pricing_engine/run_convergence_sweep.py`) that varies paths/seeds and emits JSON/CSV/HTML reports to `pricing_engine/reports/`, reusing `pricing_engine/reporting.py` meta helpers.",
        "Add corridor variance swap support by extending products in `pricing_engine/products/exotics.py` and pricing logic (surface integration in `pricing_engine/market_data/surfaces.py` plus MC fallback in `pricing_engine/numerics/monte_carlo.py`), with unit tests.",
        "Add variance/vol swap parity tests (analytic vs MC) in `tests/` and wire into existing scenarios to meet Phase 4 acceptance criteria.",
        "Add calibration stability checks and diagnostics persistence in `pricing_engine/calibration/` (bounds, fit stats, seeds), plus tests and report metadata.",
        "Implement local vol bootstrapping with arbitrage checks in `pricing_engine/market_data/` (or `pricing_engine/calibration/`) and add tests for positivity/monotonicity.",
        "Add Heston/Merton smile calibration routines in `pricing_engine/calibration/` and tests against `docs/success_metrics.md` thresholds.",
        "Document model/engine compatibility matrix updates in `docs/spec.md` and link the new tests/scripts in `docs/roadmap.md`."
      ],
      "questions": [
        "Which Phase 3/4 items are highest priority for the next iteration (path-dependent tests, MC metadata, or convergence sweep)?",
        "Do you have preferred benchmark sources/values for Asian, lookback, cliquet, and corridor regression tests?",
        "Should MC diagnostics be stored at the trade result level, the report meta level, or both?",
        "What path/seed grid should the convergence sweep use (paths list, seed list, runtime budget)?",
        "For corridor variance swaps, do you prefer a new product type or extending `VarianceSwap` with corridor bounds?",
        "What calibration accuracy targets should we apply for Heston/Merton (use `docs/success_metrics.md` as-is or tighter/looser)?"
      ],
      "risks": [
        "Limited analytic benchmarks for path-dependent products could make regression targets subjective or unstable.",
        "Monte Carlo-based tests may be flaky without strict seeding and tolerances, causing CI noise.",
        "Corridor variance swap integration depends on surface quality and may require careful extrapolation rules.",
        "Calibration routines can be ill-conditioned; added bounds may cause convergence failures without good initial guesses.",
        "Reporting schema changes may break downstream consumers if not versioned and documented."
      ]
    }
  },
  "repo_root": "/Users/evanxu/Desktop/City Mouse/Test",
  "role": "implementer",
  "round": 1,
  "run_dir": "/Users/evanxu/Desktop/City Mouse/Test/agents/runs/20260113_150000_pricing-and-product-coverage-roadmap-thi"
}
